{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! rm -rf /kaggle/working/*","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T02:25:25.280334Z","iopub.execute_input":"2025-03-16T02:25:25.280627Z","iopub.status.idle":"2025-03-16T02:25:25.405098Z","shell.execute_reply.started":"2025-03-16T02:25:25.280606Z","shell.execute_reply":"2025-03-16T02:25:25.404124Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"! git clone https://github.com/Potladurthy-Sai-Praneeth/Parllel-Speculative-Decoding.git","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T02:25:28.033827Z","iopub.execute_input":"2025-03-16T02:25:28.034134Z","iopub.status.idle":"2025-03-16T02:25:28.731478Z","shell.execute_reply.started":"2025-03-16T02:25:28.034108Z","shell.execute_reply":"2025-03-16T02:25:28.730711Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'Parllel-Speculative-Decoding'...\nremote: Enumerating objects: 129, done.\u001b[K\nremote: Counting objects: 100% (60/60), done.\u001b[K\nremote: Compressing objects: 100% (23/23), done.\u001b[K\nremote: Total 129 (delta 41), reused 50 (delta 37), pack-reused 69 (from 1)\u001b[K\nReceiving objects: 100% (129/129), 606.65 KiB | 6.07 MiB/s, done.\nResolving deltas: 100% (74/74), done.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"! sh /kaggle/working/Parllel-Speculative-Decoding/install.sh","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"! set CUDA_VISIBLE_DEVICES=0,1\n! set CUDA_LAUNCH_BLOCKING=1\n! accelerate launch /kaggle/working/Parllel-Speculative-Decoding/benchmark/eval_humaneval.py -n 2  -e output --drafts phi-1 phi-1.5 --target phi-2 --data_path /kaggle/working/Parllel-Speculative-Decoding/data/humaneval.jsonl","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"! set CUDA_VISIBLE_DEVICES=0,1\n! set CUDA_LAUNCH_BLOCKING=1\n! accelerate launch /kaggle/working/Parllel-Speculative-Decoding/benchmark/eval_mbpp.py -n 2  -e output --drafts smo-360m-instruct smo-360m --target smo-1.7b --data_path /kaggle/working/Parllel-Speculative-Decoding/data/mbpp.jsonl","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"! set CUDA_VISIBLE_DEVICES=0,1\n! set CUDA_LAUNCH_BLOCKING=1\n! accelerate launch /kaggle/working/Parllel-Speculative-Decoding/benchmark/eval_math.py -n 2  -e output --drafts smo-360m-instruct smo-360m --target smo-1.7b --data_path /kaggle/working/Parllel-Speculative-Decoding/data/math500.jsonl","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T02:25:40.662436Z","iopub.execute_input":"2025-03-16T02:25:40.662737Z","iopub.status.idle":"2025-03-16T02:29:28.858555Z","shell.execute_reply.started":"2025-03-16T02:25:40.662713Z","shell.execute_reply":"2025-03-16T02:29:28.857683Z"}},"outputs":[{"name":"stdout","text":"\u001b[93mLoading tokenizer of HuggingFaceTB/SmolLM-1.7B-Instruct...\u001b[0m\n\u001b[93mLoading Math500 data...\u001b[0m\n\u001b[92mLoaded 500 examples\u001b[0m\n\u001b[93mLoading models: \n Draft : ['HuggingFaceTB/SmolLM-360M-Instruct', 'HuggingFaceTB/SmolLM-360M']\n Target : HuggingFaceTB/SmolLM-1.7B-Instruct\u001b[0m\nconfig.json: 100%|█████████████████████████████| 724/724 [00:00<00:00, 5.04MB/s]\nconfig.json: 100%|█████████████████████████████| 738/738 [00:00<00:00, 4.80MB/s]\n2025-03-16 02:25:52.553617: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-03-16 02:25:52.553633: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-03-16 02:25:52.975145: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-03-16 02:25:52.975139: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-03-16 02:25:53.097859: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2025-03-16 02:25:53.097979: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nmodel.safetensors: 100%|██████████████████████| 724M/724M [00:04<00:00, 147MB/s]\ngeneration_config.json: 100%|██████████████████| 156/156 [00:00<00:00, 1.07MB/s]\nconfig.json: 100%|█████████████████████████████| 725/725 [00:00<00:00, 3.98MB/s]\nmodel.safetensors: 100%|████████████████████| 1.45G/1.45G [00:09<00:00, 145MB/s]\ngeneration_config.json: 100%|███████████████████| 111/111 [00:00<00:00, 704kB/s]\nmodel.safetensors: 100%|████████████████████| 3.42G/3.42G [00:22<00:00, 150MB/s]\ngeneration_config.json: 100%|███████████████████| 156/156 [00:00<00:00, 927kB/s]\n  1%|           | 3/500 [02:28<6:50:09, 49.52s/it]^C\n  1%|           | 3/500 [03:02<8:22:41, 60.69s/it]\nTraceback (most recent call last):\n  File \"/kaggle/working/Parllel-Speculative-Decoding/benchmark/eval_math.py\", line 218, in <module>\n[2025-03-16 02:29:28,152] torch.distributed.elastic.agent.server.api: [WARNING] Received Signals.SIGINT death signal, shutting down workers\n[2025-03-16 02:29:28,153] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 175 closing signal SIGINT\n      File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n[2025-03-16 02:29:28,153] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 176 closing signal SIGINT\n    return func(*args, **kwargs)\n  File \"/kaggle/working/Parllel-Speculative-Decoding/benchmark/eval_math.py\", line 155, in eval\n    generate_ids = decoding(input_ids)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n    return func(*args, **kwargs)\n  File \"/kaggle/working/Parllel-Speculative-Decoding/benchmark/../src/engine.py\", line 89, in parallel_speculative_decoding\n    x = model.generate(input_ids, self.args.gamma)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n    return func(*args, **kwargs)\n  File \"/kaggle/working/Parllel-Speculative-Decoding/benchmark/../src/kvcache4RC.py\", line 231, in generate\n    output = self._generate_with_kvcache(input, gamma)\n  File \"/kaggle/working/Parllel-Speculative-Decoding/benchmark/../src/kvcache4RC.py\", line 213, in _generate_with_kvcache\n    q = self._forward_with_kvcache(x)\n  File \"/kaggle/working/Parllel-Speculative-Decoding/benchmark/../src/kvcache4RC.py\", line 154, in _forward_with_kvcache\n    outputs = self._model(last_input_id, past_key_values=self._past_key_values, use_cache=True)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py\", line 1163, in forward\n    outputs = self.model(\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py\", line 913, in forward\n    layer_outputs = decoder_layer(\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py\", line 640, in forward\n    hidden_states, self_attn_weights, present_key_value = self.self_attn(\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py\", line 529, in forward\n    value_states = value_states.view(bsz, q_len, -1, self.head_dim).transpose(1, 2)\nKeyboardInterrupt\nTraceback (most recent call last):\n  File \"/kaggle/working/Parllel-Speculative-Decoding/benchmark/eval_math.py\", line 218, in <module>\n    alg.eval()\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n    return func(*args, **kwargs)\n  File \"/kaggle/working/Parllel-Speculative-Decoding/benchmark/eval_math.py\", line 155, in eval\n    generate_ids = decoding(input_ids)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n    return func(*args, **kwargs)\n  File \"/kaggle/working/Parllel-Speculative-Decoding/benchmark/../src/engine.py\", line 95, in parallel_speculative_decoding\n    x = model.generate(input_ids, 1)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n    return func(*args, **kwargs)\n  File \"/kaggle/working/Parllel-Speculative-Decoding/benchmark/../src/kvcache.py\", line 150, in generate\n    output = self._generate_with_kvcache(input, gamma)\n  File \"/kaggle/working/Parllel-Speculative-Decoding/benchmark/../src/kvcache.py\", line 144, in _generate_with_kvcache\n    next_tok = sample(q)\n  File \"/kaggle/working/Parllel-Speculative-Decoding/benchmark/../src/util.py\", line 142, in sample\n    idx_next = torch.multinomial(probs, num_samples=num_samples)\nKeyboardInterrupt\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"! set CUDA_VISIBLE_DEVICES=0,1\n! set CUDA_LAUNCH_BLOCKING=1\n! accelerate launch /kaggle/working/Parllel-Speculative-Decoding/benchmark/eval_humaneval.py -n 2  -e output --drafts smo-360m-instruct smo-360m --target smo-1.7b --data_path /kaggle/working/Parllel-Speculative-Decoding/data/humaneval.jsonl","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"! set CUDA_VISIBLE_DEVICES=0,1\n! set CUDA_LAUNCH_BLOCKING=1\n! accelerate launch /kaggle/working/Parllel-Speculative-Decoding/benchmark/eval_gsm8k.py -n 3  -e output --drafts qwen-0.5b-instruct qwen-0.5b-coder qwen-0.5b --target qwen-1.5b --data_path /kaggle/working/Parllel-Speculative-Decoding/data/gsm8k.jsonl","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}